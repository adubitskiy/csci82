{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow is installed and is version:  1.3.0\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tempfile\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow is installed and is version: \",  tf.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readData():\n",
    "    test = pd.read_csv('test_data.csv')\n",
    "    train = pd.read_csv('train_data.csv')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df = readData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 4584 observations with 670 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>z217</th>\n",
       "      <th>z218</th>\n",
       "      <th>z219</th>\n",
       "      <th>z220</th>\n",
       "      <th>z221</th>\n",
       "      <th>z222</th>\n",
       "      <th>subject</th>\n",
       "      <th>phase</th>\n",
       "      <th>state</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-300.361218</td>\n",
       "      <td>0.886360</td>\n",
       "      <td>-2.590886</td>\n",
       "      <td>225.001899</td>\n",
       "      <td>0.006204</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.024971</td>\n",
       "      <td>-1017.620978</td>\n",
       "      <td>-382.850838</td>\n",
       "      <td>-48.275711</td>\n",
       "      <td>-2.040336</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-297.126090</td>\n",
       "      <td>0.622211</td>\n",
       "      <td>-3.960940</td>\n",
       "      <td>220.179017</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>0.023595</td>\n",
       "      <td>91.229094</td>\n",
       "      <td>24.802230</td>\n",
       "      <td>1.783950</td>\n",
       "      <td>0.022620</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-236.460253</td>\n",
       "      <td>0.423640</td>\n",
       "      <td>-12.656341</td>\n",
       "      <td>139.453445</td>\n",
       "      <td>0.006276</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>-0.036318</td>\n",
       "      <td>-188.232347</td>\n",
       "      <td>-17.474861</td>\n",
       "      <td>-1.005571</td>\n",
       "      <td>-0.021628</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33.411458</td>\n",
       "      <td>2.854415</td>\n",
       "      <td>-1.962432</td>\n",
       "      <td>3.208911</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034184</td>\n",
       "      <td>-0.047734</td>\n",
       "      <td>185.122907</td>\n",
       "      <td>-549.282067</td>\n",
       "      <td>542.193381</td>\n",
       "      <td>-178.049926</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-118.125214</td>\n",
       "      <td>2.009809</td>\n",
       "      <td>-3.291637</td>\n",
       "      <td>34.874176</td>\n",
       "      <td>0.007598</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>35.207794</td>\n",
       "      <td>-78.143166</td>\n",
       "      <td>57.084208</td>\n",
       "      <td>-13.700212</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 670 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4          x5        x6         x7          x8        x9  \\\n",
       "0   0   0   0   1 -300.361218  0.886360  -2.590886  225.001899  0.006204   \n",
       "1   0   0   0   1 -297.126090  0.622211  -3.960940  220.179017  0.006167   \n",
       "2   0   0   0   1 -236.460253  0.423640 -12.656341  139.453445  0.006276   \n",
       "3   0   0   0   1   33.411458  2.854415  -1.962432    3.208911  0.009752   \n",
       "4   0   0   0   1 -118.125214  2.009809  -3.291637   34.874176  0.007598   \n",
       "\n",
       "        x10   ...        z217      z218         z219        z220        z221  \\\n",
       "0  0.000037   ...    0.005242  0.024971 -1017.620978 -382.850838  -48.275711   \n",
       "1 -0.000014   ...    0.001722  0.023595    91.229094   24.802230    1.783950   \n",
       "2 -0.000028   ...   -0.010894 -0.036318  -188.232347  -17.474861   -1.005571   \n",
       "3 -0.000273   ...   -0.034184 -0.047734   185.122907 -549.282067  542.193381   \n",
       "4  0.000001   ...    0.001963  0.004084    35.207794  -78.143166   57.084208   \n",
       "\n",
       "         z222  subject  phase  state  output  \n",
       "0   -2.040336        A      3      B       0  \n",
       "1    0.022620        A      3      C       0  \n",
       "2   -0.021628        A      3      B       0  \n",
       "3 -178.049926        A      3      A       0  \n",
       "4  -13.700212        A      4      C       0  \n",
       "\n",
       "[5 rows x 670 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Training data has %d observations with %d features' % train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data has 1732 observations with 669 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>z216</th>\n",
       "      <th>z217</th>\n",
       "      <th>z218</th>\n",
       "      <th>z219</th>\n",
       "      <th>z220</th>\n",
       "      <th>z221</th>\n",
       "      <th>z222</th>\n",
       "      <th>subject</th>\n",
       "      <th>phase</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.839131</td>\n",
       "      <td>2.306584</td>\n",
       "      <td>-4.655889</td>\n",
       "      <td>1.013324</td>\n",
       "      <td>0.007153</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.014684</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>325.428102</td>\n",
       "      <td>-821.094825</td>\n",
       "      <td>689.695558</td>\n",
       "      <td>-192.867397</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-21.203051</td>\n",
       "      <td>2.112956</td>\n",
       "      <td>-2.503654</td>\n",
       "      <td>1.233657</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>-0.012349</td>\n",
       "      <td>-0.029579</td>\n",
       "      <td>377.365602</td>\n",
       "      <td>-943.446587</td>\n",
       "      <td>785.687687</td>\n",
       "      <td>-217.952016</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-83.843508</td>\n",
       "      <td>2.097191</td>\n",
       "      <td>-2.625699</td>\n",
       "      <td>17.607247</td>\n",
       "      <td>0.007290</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024253</td>\n",
       "      <td>-0.014029</td>\n",
       "      <td>-0.015090</td>\n",
       "      <td>564.866863</td>\n",
       "      <td>-1445.004242</td>\n",
       "      <td>1231.304590</td>\n",
       "      <td>-349.493698</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-192.522878</td>\n",
       "      <td>0.605105</td>\n",
       "      <td>-2.468908</td>\n",
       "      <td>92.456149</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019957</td>\n",
       "      <td>-0.037490</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>-552.398720</td>\n",
       "      <td>1163.146256</td>\n",
       "      <td>-816.945306</td>\n",
       "      <td>191.395611</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-188.095799</td>\n",
       "      <td>0.390008</td>\n",
       "      <td>-4.870923</td>\n",
       "      <td>88.257844</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>-0.007101</td>\n",
       "      <td>0.025921</td>\n",
       "      <td>-860.687432</td>\n",
       "      <td>1838.968578</td>\n",
       "      <td>-1310.372483</td>\n",
       "      <td>311.393705</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 669 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   x1  x2  x3  x4          x5        x6        x7         x8        x9  \\\n",
       "0   0   0   0   1  -18.839131  2.306584 -4.655889   1.013324  0.007153   \n",
       "1   0   0   0   1  -21.203051  2.112956 -2.503654   1.233657  0.007674   \n",
       "2   0   0   0   1  -83.843508  2.097191 -2.625699  17.607247  0.007290   \n",
       "3   0   0   0   1 -192.522878  0.605105 -2.468908  92.456149  0.006284   \n",
       "4   0   0   0   1 -188.095799  0.390008 -4.870923  88.257844  0.007859   \n",
       "\n",
       "        x10  ...        z216      z217      z218        z219         z220  \\\n",
       "0  0.000055  ...    0.002809  0.014684  0.008373  325.428102  -821.094825   \n",
       "1  0.000025  ...    0.001450 -0.012349 -0.029579  377.365602  -943.446587   \n",
       "2  0.000077  ...   -0.024253 -0.014029 -0.015090  564.866863 -1445.004242   \n",
       "3  0.000007  ...    0.019957 -0.037490  0.002925 -552.398720  1163.146256   \n",
       "4 -0.000058  ...    0.007063 -0.007101  0.025921 -860.687432  1838.968578   \n",
       "\n",
       "          z221        z222  subject  phase  state  \n",
       "0   689.695558 -192.867397        B      1      B  \n",
       "1   785.687687 -217.952016        B      1      C  \n",
       "2  1231.304590 -349.493698        B      1      C  \n",
       "3  -816.945306  191.395611        B      1      C  \n",
       "4 -1310.372483  311.393705        B      1      C  \n",
       "\n",
       "[5 rows x 669 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Test data has %d observations with %d features' % test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training / validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(train_df, stratify = train_df.output, test_size = 0.10, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.copy().reset_index(drop = True)\n",
    "y_train = train_df.output\n",
    "train_df.drop('output', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_df = valid_df.copy().reset_index(drop = True)\n",
    "y_valid = valid_df.output\n",
    "valid_df.drop('output', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the numerical features to zero mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(train_df.iloc[:, :-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = scaler.transform(train_df.iloc[:, :-3])\n",
    "X_train = pd.DataFrame(X_train, columns = train_df.columns[:-3])\n",
    "X_train['subject'] = train_df.subject\n",
    "X_train['phase'] = train_df.phase\n",
    "X_train['state'] = train_df.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_valid = scaler.transform(valid_df.iloc[:, :-3])\n",
    "X_valid = pd.DataFrame(X_valid, columns = valid_df.columns[:-3])\n",
    "X_valid['subject'] = valid_df.subject\n",
    "X_valid['phase'] = valid_df.phase\n",
    "X_valid['state'] = valid_df.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = scaler.transform(test_df.iloc[:, :-3])\n",
    "X_test = pd.DataFrame(X_test, columns = test_df.columns[:-3])\n",
    "X_test['subject'] = test_df.subject\n",
    "X_test['phase'] = test_df.phase\n",
    "X_test['state'] = test_df.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare feature definitions for the tensorflow models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# categorical features\n",
    "subject = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key = \"subject\", \n",
    "    vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'k', 'L', 'M'))\n",
    "phase = tf.feature_column.categorical_column_with_identity(key='phase', num_buckets=10)\n",
    "state = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key='state', \n",
    "    vocabulary_list=('A', 'B', 'C', 'D', 'E'))\n",
    "categorical_features = [\n",
    "    tf.feature_column.indicator_column(subject), \n",
    "    tf.feature_column.indicator_column(phase), \n",
    "    tf.feature_column.indicator_column(state)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numerical features\n",
    "numerical_features = []\n",
    "for i in np.arange(1, 223):\n",
    "    numerical_features.append(tf.feature_column.numeric_column('x%d'%i))\n",
    "    numerical_features.append(tf.feature_column.numeric_column('y%d'%i))\n",
    "    numerical_features.append(tf.feature_column.numeric_column('z%d'%i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# crossed features\n",
    "subject_phase = tf.feature_column.crossed_column([\"subject\", \"phase\"], hash_bucket_size=100)\n",
    "crossed_features = [\n",
    "    tf.feature_column.indicator_column(subject_phase) \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 4125 observations with 669 features\n",
      "Validation data has 459 observations with 669 features\n"
     ]
    }
   ],
   "source": [
    "print('Training data has %d observations with %d features' % X_train.shape)\n",
    "print('Validation data has %d observations with %d features' % X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(df, labels, num_epochs, shuffle, num_):\n",
    "    return tf.estimator.inputs.pandas_input_fn(\n",
    "      x = df,\n",
    "      y  = labels,\n",
    "      batch_size = 256,\n",
    "      num_epochs = num_epochs,\n",
    "      shuffle = shuffle,\n",
    "      num_threads = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression tensorflow style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('log_model',  ignore_errors=True)\n",
    "\n",
    "log_model = tf.estimator.LinearClassifier(\n",
    "    model_dir = 'log_model',\n",
    "    # L1 regularization\n",
    "    optimizer=tf.train.FtrlOptimizer(learning_rate=0.1, l1_regularization_strength=0.001),\n",
    "    feature_columns = numerical_features + categorical_features + crossed_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.train(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train, y = y_train, batch_size = 256, num_epochs = None, shuffle = True, num_threads = 5),\n",
    "    steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_results = log_model.evaluate(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_valid, y = y_valid, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    "    steps = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(log_results):\n",
    "    print(\"%s: %s\" % (key, log_results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_predict = log_model.predict(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_test, y = None, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_results = list(log_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_hat = [r['probabilities'][1] for r in log_results]\n",
    "test_df['output'] = p_hat\n",
    "test_df[['output']].to_csv('log_solution.csv', index_label = 'id')\n",
    "test_df.drop('output', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN tensorflow style\n",
    "Using high level DNNClassifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Selecting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different dropouts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropouts = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results = []\n",
    "for dropout in dropouts:\n",
    "    \n",
    "    shutil.rmtree('tmp_model',  ignore_errors=True)\n",
    "    \n",
    "    m = tf.estimator.DNNClassifier(\n",
    "        model_dir = 'tmp_model',\n",
    "        feature_columns=numerical_features + categorical_features + crossed_features,\n",
    "        hidden_units=[1024, 512, 256],\n",
    "        dropout=dropout,\n",
    "        optimizer=tf.train.AdamOptimizer())\n",
    "    m = m.train(\n",
    "        input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "            x = X_train, y = y_train, batch_size = 256, num_epochs = None, shuffle = True, num_threads = 5),\n",
    "        steps = 200)\n",
    "    r = m.evaluate(\n",
    "        input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "            x = X_valid, y = y_valid, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    "        steps = None)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = [r['accuracy'] for r in results]\n",
    "auc = [r['auc'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dropouts, accuracy, label='accuracy')\n",
    "plt.plot(dropouts, auc, label='auc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like drooupout 0.5 produces a good model, better than the logistic regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('dnn_model',  ignore_errors=True)\n",
    "\n",
    "nn_model = tf.estimator.DNNClassifier(\n",
    "    model_dir = 'dnn_model',\n",
    "    feature_columns=numerical_features + categorical_features + crossed_features,\n",
    "    hidden_units=[512, 256, 64],\n",
    "    dropout=0.5,\n",
    "    optimizer=tf.train.AdamOptimizer()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = nn_model.train(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train, y = y_train, batch_size = 256, num_epochs = None, shuffle = True, num_threads = 5),\n",
    "    max_steps=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_results = nn_model.evaluate(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_valid, y = y_valid, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    "    steps = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(nn_results):\n",
    "    print(\"%s: %s\" % (key, nn_results[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the box NN classifier performance is not as good as the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_predict = nn_model.predict(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_test, y = None, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_results = list(nn_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_hat = [r['probabilities'][1] for r in nn_results]\n",
    "test_df['output'] = p_hat\n",
    "test_df[['output']].to_csv('nn_solution.csv', index_label = 'id')\n",
    "test_df.drop('output', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach would be to try regularization (instead of the dropouts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "regularization = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "for l1_r in regularization:\n",
    "    \n",
    "    shutil.rmtree('tmp_model',  ignore_errors=True)\n",
    "    \n",
    "    m = tf.estimator.DNNClassifier(\n",
    "        model_dir = 'tmp_model',\n",
    "        feature_columns=numerical_features + categorical_features + crossed_features,\n",
    "        hidden_units=[256, 128, 64],\n",
    "        dropout=dropout,\n",
    "        optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "            learning_rate = 0.01,\n",
    "            l1_regularization_strength = l1_r\n",
    "        )\n",
    "    )\n",
    "    m = m.train(\n",
    "        input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "            x = X_train, y = y_train, batch_size = 512, num_epochs = None, shuffle = True, num_threads = 5),\n",
    "        steps = 200)\n",
    "    r = m.evaluate(\n",
    "        input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "            x = X_valid, y = y_valid, batch_size = 512, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    "        steps = None)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = [r['accuracy'] for r in results]\n",
    "auc = [r['auc'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regularization, accuracy, label='accuracy')\n",
    "plt.plot(regularization, auc, label='auc')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller net and regularization, more training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "regularization = [0.00001, 0.0001, 0.001, 0.01, 0.1]\n",
    "for l1_r in regularization:\n",
    "    \n",
    "    shutil.rmtree('tmp_model',  ignore_errors=True)\n",
    "\n",
    "    m = tf.estimator.DNNClassifier(\n",
    "        model_dir = 'tmp_model',\n",
    "        feature_columns=numerical_features + categorical_features + crossed_features,\n",
    "        hidden_units=[256, 128],\n",
    "        dropout=dropout,\n",
    "        optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "            learning_rate = 0.01,\n",
    "            l1_regularization_strength = l1_r\n",
    "        )\n",
    "    )\n",
    "    m = m.train(\n",
    "        input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "            x = X_train, y = y_train, batch_size = 512, num_epochs = None, shuffle = True, num_threads = 5),\n",
    "        steps = 300)\n",
    "    r = m.evaluate(\n",
    "        input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "            x = X_valid, y = y_valid, batch_size = 512, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    "        steps = None)\n",
    "    results.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = [r['accuracy'] for r in results]\n",
    "auc = [r['auc'] for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(regularization, accuracy, label='accuracy')\n",
    "plt.plot(regularization, auc, label='auc')\n",
    "plt.xscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it looks like the dropout approach worked better on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Custom NN model\n",
    "Custom model with same structure as the winning dropout DNN but with a custom loss function to deal with the class imbalance. The positive class loss is reduced proportionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_model_fn(features, labels, mode, params, config):\n",
    "\n",
    "    input_layer = tf.feature_column.input_layer(\n",
    "        features = features,\n",
    "        feature_columns = numerical_features + categorical_features + crossed_features\n",
    "    )\n",
    "\n",
    "    global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "\n",
    "    x = tf.layers.dense(\n",
    "        inputs=input_layer,\n",
    "        units=1024,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"layer1\"\n",
    "    )\n",
    "\n",
    "    x = tf.layers.dropout(\n",
    "        inputs=x,\n",
    "        rate = params.dropout,\n",
    "        training = (mode == tf.estimator.ModeKeys.TRAIN),\n",
    "        name=\"dropout12\"\n",
    "    )\n",
    "\n",
    "    x = tf.layers.dense(\n",
    "        inputs=x,\n",
    "        units=512,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"layer2\"\n",
    "    )\n",
    "\n",
    "    x = tf.layers.dropout(\n",
    "        inputs=x,\n",
    "        rate = params.dropout,\n",
    "        training = (mode == tf.estimator.ModeKeys.TRAIN),\n",
    "        name=\"dropout23\"\n",
    "    )\n",
    "\n",
    "    x = tf.layers.dense(\n",
    "        inputs=x,\n",
    "        units=256,\n",
    "        activation=tf.nn.relu,\n",
    "        name=\"layer3\"\n",
    "    )\n",
    "\n",
    "    # logits for two classes\n",
    "    logits = tf.layers.dense(\n",
    "        inputs=x, \n",
    "        units=2, \n",
    "        activation=None\n",
    "    )\n",
    "\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # convert labels into one-hot encodinf array\n",
    "    # label = o, array element = [1, 0]\n",
    "    # label = 1, array element = [0, 1]\n",
    "    targets = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=2)\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.weighted_cross_entropy_with_logits(\n",
    "            targets = targets,\n",
    "            logits = logits,\n",
    "            pos_weight = 0.2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = params.learning_rate)\n",
    "        train_op = optimizer.minimize(loss=loss, global_step = tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op = train_op)\n",
    "\n",
    "    eval_metric_ops = {\n",
    "        \"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"]),\n",
    "        \"auc\": tf.metrics.auc(labels=labels, predictions=predictions[\"probabilities\"][:, 1])\n",
    "    }\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_model_dir': 'custom_model', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_secs': 600, '_session_config': None, '_tf_random_seed': 1, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "hparams = tf.contrib.training.HParams(\n",
    "    learning_rate=.01,\n",
    "    dropout = 0.5\n",
    ")\n",
    "\n",
    "shutil.rmtree('custom_model',  ignore_errors=True)\n",
    "\n",
    "custom_model = tf.estimator.Estimator(\n",
    "    model_dir = 'custom_model',\n",
    "    model_fn=custom_model_fn,\n",
    "    params=hparams\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_hook = tf.train.LoggingTensorHook(tensors = {\"probabilities\": \"softmax_tensor\"}, every_n_iter=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into custom_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.80205649  0.19794346]\n",
      " [ 0.96779668  0.03220335]\n",
      " [ 0.83222896  0.1677711 ]\n",
      " [ 0.73630959  0.26369038]\n",
      " [ 0.89389467  0.10610532]\n",
      " [ 0.81621438  0.18378562]\n",
      " [ 0.81042671  0.18957326]\n",
      " [ 0.95622182  0.04377822]\n",
      " [ 0.80781138  0.19218867]\n",
      " [ 0.9196173   0.08038273]\n",
      " [ 0.42867419  0.57132584]\n",
      " [ 0.75594819  0.24405184]\n",
      " [ 0.83246768  0.16753232]\n",
      " [ 0.79267824  0.20732169]\n",
      " [ 0.85376978  0.14623024]\n",
      " [ 0.85229534  0.14770468]\n",
      " [ 0.70796371  0.29203635]\n",
      " [ 0.99395084  0.00604916]\n",
      " [ 0.83096862  0.16903137]\n",
      " [ 0.92108417  0.07891586]\n",
      " [ 0.71087784  0.28912213]\n",
      " [ 0.88390619  0.11609384]\n",
      " [ 0.93511361  0.06488635]\n",
      " [ 0.94885617  0.05114384]\n",
      " [ 0.65646315  0.34353685]\n",
      " [ 0.98698026  0.01301973]\n",
      " [ 0.44641349  0.55358648]\n",
      " [ 0.95663011  0.04336995]\n",
      " [ 0.66858798  0.33141202]\n",
      " [ 0.75499356  0.24500647]\n",
      " [ 0.82918572  0.17081434]\n",
      " [ 0.95945716  0.04054284]\n",
      " [ 0.71650797  0.28349203]\n",
      " [ 0.86457419  0.13542584]\n",
      " [ 0.62742424  0.37257573]\n",
      " [ 0.76517117  0.2348289 ]\n",
      " [ 0.94128823  0.0587118 ]\n",
      " [ 0.77489936  0.22510065]\n",
      " [ 0.9791255   0.02087444]\n",
      " [ 0.64122593  0.35877407]\n",
      " [ 0.96475863  0.0352414 ]\n",
      " [ 0.87686372  0.12313629]\n",
      " [ 0.90870237  0.09129758]\n",
      " [ 0.94984359  0.05015646]\n",
      " [ 0.95837158  0.04162843]\n",
      " [ 0.80632424  0.19367577]\n",
      " [ 0.73491019  0.26508981]\n",
      " [ 0.8670963   0.13290371]\n",
      " [ 0.58476776  0.41523224]\n",
      " [ 0.81284022  0.18715976]\n",
      " [ 0.59657007  0.40342996]\n",
      " [ 0.38711718  0.61288279]\n",
      " [ 0.72141451  0.27858546]\n",
      " [ 0.96381456  0.03618545]\n",
      " [ 0.69894475  0.30105528]\n",
      " [ 0.98355466  0.01644532]\n",
      " [ 0.99989402  0.00010591]\n",
      " [ 0.95590967  0.04409035]\n",
      " [ 0.81244946  0.18755059]\n",
      " [ 0.5771783   0.42282164]\n",
      " [ 0.79538971  0.20461032]\n",
      " [ 0.89829034  0.10170967]\n",
      " [ 0.78501695  0.214983  ]\n",
      " [ 0.69873261  0.30126742]\n",
      " [ 0.86604226  0.13395783]\n",
      " [ 0.96316105  0.03683889]\n",
      " [ 0.8826139   0.11738604]\n",
      " [ 0.99728668  0.0027133 ]\n",
      " [ 0.68267214  0.3173278 ]\n",
      " [ 0.88627905  0.11372098]\n",
      " [ 0.93611044  0.06388956]\n",
      " [ 0.66046137  0.3395386 ]\n",
      " [ 0.76048684  0.23951319]\n",
      " [ 0.98738688  0.0126131 ]\n",
      " [ 0.88589734  0.1141027 ]\n",
      " [ 0.953695    0.04630502]\n",
      " [ 0.98284459  0.01715537]\n",
      " [ 0.73660785  0.26339215]\n",
      " [ 0.70970368  0.29029635]\n",
      " [ 0.93836808  0.06163193]\n",
      " [ 0.711299    0.28870097]\n",
      " [ 0.78201598  0.21798402]\n",
      " [ 0.94560975  0.05439027]\n",
      " [ 0.97365057  0.02634943]\n",
      " [ 0.97329289  0.02670711]\n",
      " [ 0.38146481  0.61853522]\n",
      " [ 0.82598656  0.17401347]\n",
      " [ 0.76004857  0.23995145]\n",
      " [ 0.80303526  0.1969648 ]\n",
      " [ 0.96791035  0.03208964]\n",
      " [ 0.7958644   0.2041356 ]\n",
      " [ 0.50592303  0.49407691]\n",
      " [ 0.69541478  0.30458516]\n",
      " [ 0.79489309  0.2051069 ]\n",
      " [ 0.97366297  0.02633703]\n",
      " [ 0.58791119  0.41208878]\n",
      " [ 0.77896941  0.22103062]\n",
      " [ 0.90329587  0.0967041 ]\n",
      " [ 0.93871492  0.06128512]\n",
      " [ 0.86365157  0.13634838]\n",
      " [ 0.91263217  0.08736783]\n",
      " [ 0.67562276  0.32437721]\n",
      " [ 0.73019546  0.26980457]\n",
      " [ 0.52427405  0.47572595]\n",
      " [ 0.90218908  0.09781098]\n",
      " [ 0.73139024  0.26860976]\n",
      " [ 0.90046656  0.09953345]\n",
      " [ 0.80826777  0.19173221]\n",
      " [ 0.94204688  0.05795318]\n",
      " [ 0.90220374  0.09779627]\n",
      " [ 0.86072969  0.13927032]\n",
      " [ 0.8829782   0.11702185]\n",
      " [ 0.6051681   0.3948319 ]\n",
      " [ 0.99729961  0.00270046]\n",
      " [ 0.81550127  0.18449874]\n",
      " [ 0.82567418  0.17432579]\n",
      " [ 0.72951257  0.27048746]\n",
      " [ 0.80846167  0.19153832]\n",
      " [ 0.85748088  0.14251904]\n",
      " [ 0.83761209  0.16238792]\n",
      " [ 0.77271199  0.22728801]\n",
      " [ 0.55602628  0.44397381]\n",
      " [ 0.83571345  0.16428657]\n",
      " [ 0.44193092  0.55806905]\n",
      " [ 0.92978996  0.07021003]\n",
      " [ 0.56119275  0.43880728]\n",
      " [ 0.68868256  0.31131744]\n",
      " [ 0.9292053   0.07079468]\n",
      " [ 0.94362867  0.05637133]\n",
      " [ 0.94687831  0.05312165]\n",
      " [ 0.73763466  0.26236534]\n",
      " [ 0.95883161  0.04116838]\n",
      " [ 0.63983947  0.36016056]\n",
      " [ 0.99634057  0.00365941]\n",
      " [ 0.81715494  0.182845  ]\n",
      " [ 0.73593301  0.26406702]\n",
      " [ 0.62193805  0.37806204]\n",
      " [ 0.94169122  0.05830874]\n",
      " [ 0.95611542  0.04388455]\n",
      " [ 0.87568116  0.12431879]\n",
      " [ 0.95654786  0.04345215]\n",
      " [ 0.73506534  0.26493475]\n",
      " [ 0.7619409   0.23805913]\n",
      " [ 0.93543416  0.06456587]\n",
      " [ 0.62518597  0.37481409]\n",
      " [ 0.89826602  0.10173405]\n",
      " [ 0.5775733   0.4224267 ]\n",
      " [ 0.41436723  0.5856328 ]\n",
      " [ 0.67962784  0.3203721 ]\n",
      " [ 0.73405123  0.26594883]\n",
      " [ 0.96965885  0.03034114]\n",
      " [ 0.80949891  0.19050109]\n",
      " [ 0.92971754  0.07028242]\n",
      " [ 0.79297948  0.20702057]\n",
      " [ 0.87063408  0.12936595]\n",
      " [ 0.52116102  0.47883892]\n",
      " [ 0.66669536  0.33330455]\n",
      " [ 0.97696632  0.02303372]\n",
      " [ 0.98004121  0.01995881]\n",
      " [ 0.58081818  0.41918179]\n",
      " [ 0.31396818  0.68603176]\n",
      " [ 0.80387002  0.19612999]\n",
      " [ 0.87070489  0.12929511]\n",
      " [ 0.7882455   0.21175455]\n",
      " [ 0.9283042   0.07169581]\n",
      " [ 0.66021246  0.33978757]\n",
      " [ 0.82278055  0.17721945]\n",
      " [ 0.67003375  0.32996622]\n",
      " [ 0.75381655  0.24618347]\n",
      " [ 0.94599503  0.05400493]\n",
      " [ 0.57893419  0.42106578]\n",
      " [ 0.43045911  0.56954092]\n",
      " [ 0.69140756  0.30859247]\n",
      " [ 0.83180994  0.16819002]\n",
      " [ 0.82200652  0.17799351]\n",
      " [ 0.76370221  0.23629783]\n",
      " [ 0.99967349  0.00032658]\n",
      " [ 0.60484523  0.39515483]\n",
      " [ 0.82677013  0.17322984]\n",
      " [ 0.81705964  0.18294042]\n",
      " [ 0.82984751  0.17015254]\n",
      " [ 0.9107691   0.08923088]\n",
      " [ 0.73997754  0.26002246]\n",
      " [ 0.77301264  0.22698738]\n",
      " [ 0.59236205  0.40763804]\n",
      " [ 0.45237818  0.54762185]\n",
      " [ 0.96781206  0.03218789]\n",
      " [ 0.93680406  0.063196  ]\n",
      " [ 0.78592283  0.21407717]\n",
      " [ 0.84334892  0.15665111]\n",
      " [ 0.53679931  0.46320072]\n",
      " [ 0.94825     0.05175008]\n",
      " [ 0.83004832  0.16995165]\n",
      " [ 0.76063871  0.23936127]\n",
      " [ 0.93294948  0.06705053]\n",
      " [ 0.95786959  0.04213037]\n",
      " [ 0.57485509  0.42514491]\n",
      " [ 0.60299551  0.39700449]\n",
      " [ 0.84958732  0.15041263]\n",
      " [ 0.68447948  0.31552055]\n",
      " [ 0.87193161  0.1280684 ]\n",
      " [ 0.62955898  0.37044102]\n",
      " [ 0.71318507  0.28681496]\n",
      " [ 0.97431427  0.02568574]\n",
      " [ 0.97589093  0.02410914]\n",
      " [ 0.80038893  0.19961108]\n",
      " [ 0.8675586   0.13244146]\n",
      " [ 0.85084653  0.1491535 ]\n",
      " [ 0.9989084   0.00109158]\n",
      " [ 0.72610319  0.27389678]\n",
      " [ 0.96902329  0.03097667]\n",
      " [ 0.90895355  0.09104642]\n",
      " [ 0.8437891   0.15621084]\n",
      " [ 0.87828887  0.12171113]\n",
      " [ 0.68402159  0.31597841]\n",
      " [ 0.95047802  0.04952198]\n",
      " [ 0.87245941  0.12754057]\n",
      " [ 0.80347502  0.19652496]\n",
      " [ 0.89280945  0.10719056]\n",
      " [ 0.74438781  0.25561219]\n",
      " [ 0.96878469  0.03121525]\n",
      " [ 0.48600841  0.51399153]\n",
      " [ 0.45135134  0.54864866]\n",
      " [ 0.78526002  0.21473996]\n",
      " [ 0.9038223   0.09617773]\n",
      " [ 0.85888147  0.14111848]\n",
      " [ 0.80751014  0.19248988]\n",
      " [ 0.73258591  0.26741415]\n",
      " [ 0.95640904  0.043591  ]\n",
      " [ 0.99340951  0.00659046]\n",
      " [ 0.79895782  0.20104215]\n",
      " [ 0.89264172  0.10735825]\n",
      " [ 0.8090328   0.19096719]\n",
      " [ 0.59334558  0.40665448]\n",
      " [ 0.95868164  0.04131843]\n",
      " [ 0.94615048  0.0538495 ]\n",
      " [ 0.9926213   0.00737873]\n",
      " [ 0.82889909  0.17110088]\n",
      " [ 0.66918945  0.33081058]\n",
      " [ 0.44979101  0.55020899]\n",
      " [ 0.95588404  0.04411594]\n",
      " [ 0.91373038  0.08626962]\n",
      " [ 0.81164533  0.18835463]\n",
      " [ 0.98634952  0.01365039]\n",
      " [ 0.87582445  0.12417558]\n",
      " [ 0.75764823  0.24235171]\n",
      " [ 0.67510837  0.3248916 ]\n",
      " [ 0.88473159  0.11526845]\n",
      " [ 0.88073701  0.11926293]\n",
      " [ 0.58976769  0.41023234]\n",
      " [ 0.93863422  0.06136572]\n",
      " [ 0.94135308  0.0586469 ]\n",
      " [ 0.88348305  0.11651698]\n",
      " [ 0.93811488  0.0618852 ]\n",
      " [ 0.81825602  0.1817439 ]\n",
      " [ 0.74660331  0.25339666]]\n",
      "INFO:tensorflow:step = 1, loss = 0.568429\n",
      "INFO:tensorflow:global_step/sec: 4.30058\n",
      "INFO:tensorflow:step = 101, loss = 0.108905 (23.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.46482\n",
      "INFO:tensorflow:step = 201, loss = 0.108459 (22.402 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.03822515  0.96177489]\n",
      " [ 0.00006193  0.99993801]\n",
      " [ 0.30907646  0.69092357]\n",
      " [ 0.00005253  0.99994743]\n",
      " [ 0.00534427  0.99465573]\n",
      " [ 0.0000045   0.99999547]\n",
      " [ 0.00000164  0.99999833]\n",
      " [ 0.00027577  0.99972421]\n",
      " [ 0.02680779  0.97319216]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.08297194  0.91702807]\n",
      " [ 0.76962543  0.23037459]\n",
      " [ 0.00179665  0.9982034 ]\n",
      " [ 0.00007793  0.99992204]\n",
      " [ 0.50145888  0.49854112]\n",
      " [ 0.10931016  0.89068985]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.57275498  0.42724511]\n",
      " [ 0.00046815  0.99953187]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01616992  0.98383015]\n",
      " [ 0.00003409  0.99996591]\n",
      " [ 0.18183899  0.81816101]\n",
      " [ 0.01695474  0.98304522]\n",
      " [ 0.00854636  0.99145365]\n",
      " [ 0.52652317  0.4734768 ]\n",
      " [ 0.00001636  0.99998367]\n",
      " [ 0.11940193  0.88059807]\n",
      " [ 0.00100047  0.99899954]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00089551  0.99910444]\n",
      " [ 0.66734582  0.33265415]\n",
      " [ 0.00046183  0.99953818]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00538887  0.99461114]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00000037  0.99999964]\n",
      " [ 0.00000005  1.        ]\n",
      " [ 0.02933735  0.97066259]\n",
      " [ 0.01651959  0.98348039]\n",
      " [ 0.00481717  0.99518281]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.02282681  0.97717321]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01807259  0.98192745]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.25439429  0.74560565]\n",
      " [ 0.78852767  0.21147229]\n",
      " [ 0.02859561  0.97140437]\n",
      " [ 0.01291484  0.98708516]\n",
      " [ 0.15498152  0.84501845]\n",
      " [ 0.00112527  0.99887472]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.32644632  0.67355365]\n",
      " [ 0.00002359  0.9999764 ]\n",
      " [ 0.00000055  0.9999994 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00329613  0.99670392]\n",
      " [ 0.00000194  0.99999809]\n",
      " [ 0.00001767  0.99998236]\n",
      " [ 0.00003286  0.9999671 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.90492404  0.09507596]\n",
      " [ 0.00142845  0.99857152]\n",
      " [ 0.10753713  0.89246285]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.0007822   0.99921775]\n",
      " [ 0.59381008  0.40618986]\n",
      " [ 0.00000841  0.99999154]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.47648838  0.52351165]\n",
      " [ 0.00146638  0.99853361]\n",
      " [ 0.14402138  0.85597867]\n",
      " [ 0.65368003  0.34631997]\n",
      " [ 0.04194015  0.95805985]\n",
      " [ 0.09047359  0.90952647]\n",
      " [ 0.00033559  0.99966443]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.          1.        ]\n",
      " [ 0.58737707  0.41262293]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01527908  0.98472089]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01311788  0.98688215]\n",
      " [ 0.11103298  0.88896698]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00044368  0.99955636]\n",
      " [ 0.00011634  0.99988365]\n",
      " [ 0.          1.        ]\n",
      " [ 0.36601737  0.6339826 ]\n",
      " [ 0.00001081  0.99998915]\n",
      " [ 0.62144059  0.37855938]\n",
      " [ 0.00000038  0.99999964]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00000134  0.99999869]\n",
      " [ 0.06209389  0.93790615]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00490498  0.99509501]\n",
      " [ 0.43982822  0.56017178]\n",
      " [ 0.22444096  0.77555907]\n",
      " [ 0.03086003  0.96913993]\n",
      " [ 0.10577738  0.89422268]\n",
      " [ 0.05180128  0.94819874]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00000374  0.9999963 ]\n",
      " [ 0.00013176  0.99986827]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00046014  0.99953985]\n",
      " [ 0.56122482  0.43877515]\n",
      " [ 0.01578789  0.9842121 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00005823  0.99994171]\n",
      " [ 0.58765948  0.41234052]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01853769  0.98146224]\n",
      " [ 0.7544046   0.24559544]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.59337366  0.40662625]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01756487  0.98243517]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00641619  0.99358386]\n",
      " [ 0.00062854  0.99937147]\n",
      " [ 0.20084479  0.79915518]\n",
      " [ 0.0088283   0.99117166]\n",
      " [ 0.0235306   0.97646934]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00233527  0.99766469]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00000434  0.99999571]\n",
      " [ 0.06761421  0.9323858 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00070139  0.99929857]\n",
      " [ 0.10105674  0.89894331]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00835128  0.99164867]\n",
      " [ 0.01635422  0.9836458 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00824787  0.99175209]\n",
      " [ 0.00376252  0.9962374 ]\n",
      " [ 0.12797153  0.87202847]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.02632022  0.97367984]\n",
      " [ 0.02110868  0.97889131]\n",
      " [ 0.00938075  0.99061918]\n",
      " [ 0.03778047  0.96221954]\n",
      " [ 0.15525536  0.84474462]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.04366375  0.95633626]\n",
      " [ 0.00244753  0.99755245]\n",
      " [ 0.1239158   0.87608421]\n",
      " [ 0.0003923   0.99960774]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01470537  0.98529458]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00641537  0.99358457]\n",
      " [ 0.00034738  0.99965262]\n",
      " [ 0.02168764  0.97831237]\n",
      " [ 0.0219279   0.97807217]\n",
      " [ 0.0352144   0.96478558]\n",
      " [ 0.00193202  0.99806803]\n",
      " [ 0.48469675  0.51530325]\n",
      " [ 0.00022835  0.99977165]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00006447  0.99993551]\n",
      " [ 0.20388114  0.79611886]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00017938  0.99982065]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00022155  0.99977845]\n",
      " [ 0.00056485  0.99943513]\n",
      " [ 0.05554207  0.94445789]\n",
      " [ 0.          1.        ]\n",
      " [ 0.66308212  0.33691791]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.20562309  0.79437697]\n",
      " [ 0.00000366  0.9999963 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.0449459   0.9550541 ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00002571  0.99997425]\n",
      " [ 0.00336432  0.99663574]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00055001  0.99945003]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.00006135  0.99993861]\n",
      " [ 0.07138265  0.92861736]\n",
      " [ 0.19659331  0.80340672]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.01384235  0.98615766]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.03648771  0.9635123 ]\n",
      " [ 0.00001149  0.99998856]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00011685  0.99988317]\n",
      " [ 0.00000148  0.99999857]\n",
      " [ 0.00001085  0.99998915]\n",
      " [ 0.00047872  0.99952126]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00212694  0.99787307]\n",
      " [ 0.00031106  0.99968898]\n",
      " [ 0.33296686  0.6670332 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00062737  0.99937266]\n",
      " [ 0.03382413  0.96617579]\n",
      " [ 0.00560686  0.99439311]\n",
      " [ 0.00046796  0.9995321 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.19385767  0.80614239]\n",
      " [ 0.03790162  0.96209836]\n",
      " [ 0.29004639  0.70995361]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00321118  0.99678886]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.14136274  0.85863727]\n",
      " [ 0.00000465  0.99999535]\n",
      " [ 0.00079532  0.9992047 ]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.16660962  0.83339041]\n",
      " [ 0.0004317   0.99956828]\n",
      " [ 0.47924206  0.52075797]\n",
      " [ 0.00044819  0.99955183]\n",
      " [ 0.00187303  0.99812692]\n",
      " [ 0.00002363  0.9999764 ]\n",
      " [ 0.00000824  0.99999177]\n",
      " [ 0.01750042  0.9824996 ]\n",
      " [ 0.00112986  0.99887007]\n",
      " [ 0.000192    0.99980801]\n",
      " [ 0.20856237  0.79143763]\n",
      " [ 0.00000045  0.99999952]\n",
      " [ 0.00821354  0.99178642]\n",
      " [ 0.14247224  0.85752779]\n",
      " [ 0.00030567  0.99969435]\n",
      " [ 0.14247224  0.85752779]] (57.331 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.27158\n",
      "INFO:tensorflow:step = 301, loss = 0.083393 (23.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48842\n",
      "INFO:tensorflow:step = 401, loss = 0.0659096 (22.325 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.45047\n",
      "INFO:tensorflow:probabilities = [[ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00003611  0.99996388]\n",
      " [ 0.00115155  0.99884844]\n",
      " [ 0.00000015  0.99999988]\n",
      " [ 0.01334421  0.98665583]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00001767  0.99998236]\n",
      " [ 0.63332218  0.36667788]\n",
      " [ 0.00000028  0.99999976]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00914151  0.9908585 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03651742  0.96348256]\n",
      " [ 0.00140649  0.99859351]\n",
      " [ 0.0000036   0.99999642]\n",
      " [ 0.0000584   0.99994159]\n",
      " [ 0.00002415  0.9999758 ]\n",
      " [ 0.0000105   0.99998951]\n",
      " [ 0.00411035  0.99588972]\n",
      " [ 0.45132065  0.54867935]\n",
      " [ 0.99995148  0.00004857]\n",
      " [ 0.0265502   0.97344977]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000011  0.99999988]\n",
      " [ 0.00109259  0.99890745]\n",
      " [ 0.00000292  0.99999714]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00000298  0.99999702]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.1764037   0.82359624]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.37895587  0.6210441 ]\n",
      " [ 0.00051521  0.99948478]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.05286605  0.94713396]\n",
      " [ 0.00202559  0.99797446]\n",
      " [ 0.          1.        ]\n",
      " [ 0.10628555  0.89371449]\n",
      " [ 0.01609767  0.98390239]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00001187  0.99998808]\n",
      " [ 0.00000338  0.99999666]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00001835  0.99998164]\n",
      " [ 0.79976678  0.20023319]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00083626  0.99916375]\n",
      " [ 0.00000946  0.99999058]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.06220889  0.93779111]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00015677  0.99984324]\n",
      " [ 0.00000093  0.99999905]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00266856  0.9973315 ]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.00068875  0.99931121]\n",
      " [ 0.00013026  0.9998697 ]\n",
      " [ 0.0004246   0.99957544]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.0000036   0.99999642]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000071  0.99999928]\n",
      " [ 0.00016778  0.99983215]\n",
      " [ 0.00002744  0.99997258]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.91199654  0.08800347]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.0000003   0.99999976]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96997178  0.03002818]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00184272  0.99815732]\n",
      " [ 0.0867798   0.91322023]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00018783  0.99981219]\n",
      " [ 0.00000008  0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000004  1.        ]\n",
      " [ 0.17679462  0.82320541]\n",
      " [ 0.00000042  0.99999952]\n",
      " [ 0.00000008  0.99999988]\n",
      " [ 0.16484824  0.83515173]\n",
      " [ 0.00003544  0.99996459]\n",
      " [ 0.35434493  0.64565504]\n",
      " [ 0.63250858  0.36749139]\n",
      " [ 0.00425388  0.99574608]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.006292    0.99370801]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00012492  0.99987507]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00000078  0.99999917]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00000419  0.99999583]\n",
      " [ 0.00000005  1.        ]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.00092594  0.99907398]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00000082  0.99999917]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02215812  0.97784185]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.94348246  0.05651754]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.56254184  0.43745819]\n",
      " [ 0.          1.        ]\n",
      " [ 0.08387613  0.91612387]\n",
      " [ 0.00002983  0.9999702 ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00003462  0.99996543]\n",
      " [ 0.          1.        ]\n",
      " [ 0.25768325  0.74231672]\n",
      " [ 0.00003854  0.9999615 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000009  0.99999988]\n",
      " [ 0.0000001   0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00005654  0.99994349]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.15871219  0.84128785]\n",
      " [ 0.12691286  0.87308711]\n",
      " [ 0.00140475  0.99859518]\n",
      " [ 0.00103601  0.99896395]\n",
      " [ 0.06001256  0.93998748]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00218238  0.99781764]\n",
      " [ 0.00000007  0.99999988]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000006  1.        ]\n",
      " [ 0.00000089  0.99999917]\n",
      " [ 0.14442278  0.85557723]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.01763642  0.98236358]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00905551  0.9909445 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.03297788  0.96702206]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.02289088  0.97710913]\n",
      " [ 0.03809132  0.96190864]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00185195  0.99814808]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00175882  0.99824119]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.00003181  0.99996817]\n",
      " [ 0.00000014  0.99999988]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000192  0.99999809]\n",
      " [ 0.00587476  0.99412525]\n",
      " [ 0.00209517  0.9979049 ]\n",
      " [ 0.00000495  0.99999499]\n",
      " [ 0.06938815  0.93061185]\n",
      " [ 0.0074975   0.99250245]\n",
      " [ 0.00436591  0.99563402]\n",
      " [ 0.41312701  0.58687299]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02030971  0.97969031]\n",
      " [ 0.          1.        ]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00468878  0.9953112 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.33595407  0.66404593]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96023726  0.03976266]\n",
      " [ 0.00098625  0.99901378]\n",
      " [ 0.99999464  0.00000532]\n",
      " [ 0.16611175  0.83388823]\n",
      " [ 0.05538354  0.9446165 ]\n",
      " [ 0.00000796  0.99999201]\n",
      " [ 0.00000425  0.99999571]] (56.506 sec)\n",
      "INFO:tensorflow:step = 501, loss = 0.0767918 (22.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40498\n",
      "INFO:tensorflow:step = 601, loss = 0.0724885 (22.696 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.40091\n",
      "INFO:tensorflow:step = 701, loss = 0.0625174 (22.714 sec)\n",
      "INFO:tensorflow:probabilities = [[ 0.          1.        ]\n",
      " [ 0.12405574  0.87594426]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000139  0.99999857]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.89019507  0.10980497]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.10632589  0.89367414]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000489  0.99999511]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.99716043  0.00283962]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04791848  0.9520815 ]\n",
      " [ 0.83464485  0.16535516]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000057  0.9999994 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.0104701   0.98952991]\n",
      " [ 0.99995899  0.00004105]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00012861  0.99987137]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00042331  0.99957663]\n",
      " [ 0.00022912  0.99977094]\n",
      " [ 0.00009631  0.99990368]\n",
      " [ 0.00181135  0.99818867]\n",
      " [ 0.00112485  0.99887508]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.00000033  0.99999964]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.03096292  0.96903706]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00855589  0.99144417]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.05098223  0.94901776]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000006  0.99999988]\n",
      " [ 0.02852208  0.97147793]\n",
      " [ 0.06626822  0.93373179]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.03655777  0.96344227]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.03640295  0.96359712]\n",
      " [ 0.00000047  0.99999952]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.81478614  0.18521385]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000024  0.99999976]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02773161  0.97226834]\n",
      " [ 0.00000016  0.99999988]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.98508769  0.01491231]\n",
      " [ 0.00000027  0.99999976]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.00001662  0.99998343]\n",
      " [ 0.00000115  0.99999881]\n",
      " [ 0.00000656  0.99999344]\n",
      " [ 0.99963391  0.00036604]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00038005  0.99961996]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000009  0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00001003  0.99998999]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00032942  0.99967062]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000031  0.99999964]\n",
      " [ 0.          1.        ]\n",
      " [ 0.07001369  0.92998636]\n",
      " [ 0.00000543  0.99999452]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00001821  0.99998176]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.93820518  0.06179477]\n",
      " [ 0.00000016  0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.0000001   0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.98717344  0.01282659]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00004687  0.99995315]\n",
      " [ 0.00000481  0.99999523]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000044  0.99999952]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000005  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.08467015  0.91532981]\n",
      " [ 0.00076198  0.99923801]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00010667  0.99989331]\n",
      " [ 0.0000038   0.99999619]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.0000101   0.99998987]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000528  0.99999475]\n",
      " [ 0.00019021  0.9998098 ]\n",
      " [ 0.00911963  0.99088037]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99980479  0.00019517]\n",
      " [ 0.00000014  0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000005  1.        ]\n",
      " [ 0.00000454  0.99999547]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.26348463  0.73651534]\n",
      " [ 0.00030641  0.99969363]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.0187503   0.98124975]\n",
      " [ 0.06020378  0.93979621]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000003  1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000069  0.99999928]\n",
      " [ 0.0000019   0.99999809]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000063  0.9999994 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000531  0.99999464]\n",
      " [ 0.00171049  0.99828953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.81922323  0.18077679]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000018  0.99999976]\n",
      " [ 0.00207732  0.99792272]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00010466  0.99989533]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.49423888  0.50576115]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00000026  0.99999976]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.00014874  0.99985123]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.70130241  0.29869759]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99995756  0.0000424 ]\n",
      " [ 0.08592059  0.91407937]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00148931  0.99851066]\n",
      " [ 0.00000294  0.99999702]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00297167  0.99702841]\n",
      " [ 0.00520217  0.99479783]\n",
      " [ 0.          1.        ]\n",
      " [ 0.12846051  0.87153953]\n",
      " [ 0.12846051  0.87153953]] (56.487 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 4.44078\n",
      "INFO:tensorflow:step = 801, loss = 0.0728116 (22.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.43153\n",
      "INFO:tensorflow:step = 901, loss = 0.0562863 (22.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.48258\n",
      "INFO:tensorflow:probabilities = [[ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09155475  0.90844524]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000184  0.99999821]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00007254  0.9999274 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00178141  0.9982186 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.83210289  0.16789709]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00002306  0.99997699]\n",
      " [ 0.40039104  0.59960902]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000013  0.99999988]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.62171698  0.37828311]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000048  0.99999952]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00041794  0.99958211]\n",
      " [ 0.00000147  0.99999857]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00181608  0.99818391]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.9918229   0.00817707]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.97872514  0.02127486]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.0008493   0.99915063]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.87750357  0.12249634]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99060011  0.00939981]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.0000015   0.99999845]\n",
      " [ 0.          1.        ]\n",
      " [ 0.26103109  0.73896891]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000171  0.99999833]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00199928  0.99800068]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00008919  0.99991083]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00001096  0.99998903]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000073  0.99999928]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000912  0.99999094]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00090186  0.99909818]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000012  0.99999988]\n",
      " [ 0.00609057  0.99390936]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000445  0.99999559]\n",
      " [ 0.00032904  0.99967098]\n",
      " [ 0.00000023  0.99999976]\n",
      " [ 0.00016351  0.99983644]\n",
      " [ 0.00017708  0.99982291]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00040464  0.99959534]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.01398566  0.98601437]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.9919247   0.00807533]\n",
      " [ 0.86839932  0.13160071]\n",
      " [ 0.00072683  0.99927312]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00012928  0.99987066]\n",
      " [ 0.00000736  0.99999261]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.99839455  0.00160547]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00015565  0.99984431]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.10448142  0.89551854]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00001556  0.99998438]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02262215  0.97737783]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00063937  0.99936062]\n",
      " [ 0.01122782  0.98877221]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.04870378  0.95129621]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00175633  0.99824369]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000017  0.99999988]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00482219  0.99517787]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.01097329  0.98902673]\n",
      " [ 0.          1.        ]\n",
      " [ 0.02161963  0.97838038]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.9999814   0.00001856]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.00085947  0.9991405 ]\n",
      " [ 0.00000006  0.99999988]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84960353  0.1503965 ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.00385821  0.99614185]\n",
      " [ 0.          1.        ]\n",
      " [ 0.39431599  0.60568398]\n",
      " [ 0.01691975  0.98308027]\n",
      " [ 0.00000102  0.99999893]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.63020444  0.36979553]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.02949614  0.97050381]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00008674  0.99991322]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00001266  0.99998736]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000002  1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.021699    0.97830099]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.96490234  0.03509764]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.09376894  0.90623111]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000061  0.9999994 ]\n",
      " [ 0.99242485  0.00757515]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000022  0.99999976]\n",
      " [ 0.00182984  0.99817014]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000093  0.99999905]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000185  0.99999821]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00000118  0.99999881]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.00000001  1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.00003446  0.99996555]\n",
      " [ 0.9979735   0.00202645]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]\n",
      " [ 0.          1.        ]\n",
      " [ 0.18340282  0.81659716]] (56.353 sec)\n",
      "INFO:tensorflow:step = 1001, loss = 0.0614239 (22.343 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into custom_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0614239.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x1b02c2b6e48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.train(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_train, y = y_train, batch_size = 256, num_epochs = None, shuffle = True, num_threads = 5),\n",
    "    steps=1001,\n",
    "    hooks=[logging_hook]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-10-30-16:06:53\n",
      "INFO:tensorflow:Restoring parameters from custom_model\\model.ckpt-1001\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-30-16:06:58\n",
      "INFO:tensorflow:Saving dict for global step 1001: accuracy = 0.847495, auc = 0.737349, global_step = 1001, loss = 0.175602\n"
     ]
    }
   ],
   "source": [
    "custom_results = custom_model.evaluate(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_valid, y = y_valid, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    "    steps = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_predict = custom_model.predict(\n",
    "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
    "        x = X_test, y = None, batch_size = 256, num_epochs = 1, shuffle = False, num_threads = 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from custom_model\\model.ckpt-1001\n"
     ]
    }
   ],
   "source": [
    "custom_results = list(custom_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_hat = [r['probabilities'][1] for r in custom_results]\n",
    "test_df['output'] = p_hat\n",
    "test_df[['output']].to_csv('custom_solution.csv', index_label = 'id')\n",
    "test_df.drop('output', inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
