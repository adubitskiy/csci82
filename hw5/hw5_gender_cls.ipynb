{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework #5\n",
    "### Using LSA to train a classifier for character gender recognition in Shakespeare plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.externals.joblib import Memory\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to download punkt, our sentence tokenizer, and also a dictionary of stopwords that we'll use later to remove stopwords from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll also need to find and assign genders to all characters and their associated texts. We'll use [this list of female characters](http://www.shakespeareswords.com/Special-Features-Female-Characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_characters_df = pd.read_csv(\"female_characters.csv\")\n",
    "female_characters_df.character = female_characters_df.character.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>play_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>replics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>katharine</td>\n",
       "      <td>Love's Labours Lost</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>daughter</td>\n",
       "      <td>Pericles, Prince of Tyre</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daughter</td>\n",
       "      <td>The Two Noble Kinsmen</td>\n",
       "      <td>Female</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     character                 play_name  gender  replics\n",
       "93   katharine       Love's Labours Lost  Female       46\n",
       "164   daughter  Pericles, Prince of Tyre  Female        2\n",
       "12    daughter     The Two Noble Kinsmen  Female      324"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_characters_df.sample(n= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll de-serialize the data streams from our pickle file, which contain all texts from all of Shakespeare's plays along with the associated play, speaker, act/scene, and play genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('shakespeare_plays.pickle', 'rb') as handle:\n",
    "    speeches = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(speeches)\n",
    "speeches_df.speaker = speeches_df.speaker.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>genre</th>\n",
       "      <th>play_name</th>\n",
       "      <th>scene</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_number</th>\n",
       "      <th>speech_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>2</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Taming of the Shrew</td>\n",
       "      <td>1</td>\n",
       "      <td>Padua. A room in BAPTISTA'S house.</td>\n",
       "      <td>katharina</td>\n",
       "      <td>57</td>\n",
       "      <td>No such jade as you, if me you mean.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16417</th>\n",
       "      <td>3</td>\n",
       "      <td>History</td>\n",
       "      <td>Richard II</td>\n",
       "      <td>2</td>\n",
       "      <td>The coast of Wales. A castle in view.</td>\n",
       "      <td>duke of aumerle</td>\n",
       "      <td>28</td>\n",
       "      <td>My liege, one word.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16682</th>\n",
       "      <td>5</td>\n",
       "      <td>History</td>\n",
       "      <td>Richard II</td>\n",
       "      <td>6</td>\n",
       "      <td>Windsor castle.</td>\n",
       "      <td>henry bolingbroke</td>\n",
       "      <td>5</td>\n",
       "      <td>Thy pains, Fitzwater, shall not be forgot;\\nRi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      act    genre            play_name scene  \\\n",
       "9222    2   Comedy  Taming of the Shrew     1   \n",
       "16417   3  History           Richard II     2   \n",
       "16682   5  History           Richard II     6   \n",
       "\n",
       "                                  scene_name            speaker speech_number  \\\n",
       "9222      Padua. A room in BAPTISTA'S house.          katharina            57   \n",
       "16417  The coast of Wales. A castle in view.    duke of aumerle            28   \n",
       "16682                        Windsor castle.  henry bolingbroke             5   \n",
       "\n",
       "                                             speech_text  \n",
       "9222                No such jade as you, if me you mean.  \n",
       "16417                                My liege, one word.  \n",
       "16682  Thy pains, Fitzwater, shall not be forgot;\\nRi...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.sample(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also double check that our list of plays are the same as the plays listed in the genders dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"All's Well That Ends Well\", \"Love's Labours Lost\", 'Two Gentlemen of Verona', 'Troilus and Cressida', 'Macbeth', 'Othello', 'Henry V', 'Coriolanus', 'Richard III', 'King John', 'The Merchant of Venice', 'TheMerry Wives of Windsor', 'Titus Andronicus', 'Timon of Athens', 'Julius Caesar', 'Twelfth Night', \"Winter's Tale\", 'The Comedy of Errors', 'Henry VIII', \"A Midsummer Night's Dream\", 'Much Ado About Nothing', 'The Tempest', 'Pericles, Prince of Tyre', 'As You Like It', 'Taming of the Shrew', 'Measure for Measure', 'Hamlet', 'Romeo and Juliet', 'Richard II', 'Antony and Cleopatra', 'King Lear', 'Cymbeline'}\n"
     ]
    }
   ],
   "source": [
    "our_names = set(speeches_df.play_name)\n",
    "print(our_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "their_names = set(female_characters_df.play_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"All's Well That Ends Well\", \"Love's Labours Lost\", 'Two Gentlemen of Verona', 'Troilus and Cressida', 'Othello', 'Macbeth', 'The Two Noble Kinsmen', 'Henry V', 'Coriolanus', 'Richard III', 'King John', 'The Merchant of Venice', 'TheMerry Wives of Windsor', 'Titus Andronicus', 'Timon of Athens', 'Julius Caesar', 'Twelfth Night', \"Winter's Tale\", 'The Comedy of Errors', 'Henry VIII', \"A Midsummer Night's Dream\", 'Much Ado About Nothing', 'Henry VI', 'The Tempest', 'Pericles, Prince of Tyre', 'As You Like It', 'Taming of the Shrew', 'Measure for Measure', 'Hamlet', 'Romeo and Juliet', 'Richard II', 'Antony and Cleopatra', 'King Edward III', 'Henry IV', 'King Lear', 'Cymbeline'}\n"
     ]
    }
   ],
   "source": [
    "print(their_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to see if our texts include any plays that aren't included in the genders dataframe and note that there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(our_names - their_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, it looks like the additional plays in the genders dataframe are those that Shakespeare co-authored, so looks we're looking okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Henry IV', 'King Edward III', 'Henry VI', 'The Two Noble Kinsmen'}\n"
     ]
    }
   ],
   "source": [
    "print(their_names - our_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create sets of our speakers and add a 'female' column to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_speakers = set(speeches_df.speaker)\n",
    "their_speakers = set(female_characters_df.character)\n",
    "\n",
    "speeches_df['female'] = speeches_df.apply(lambda r : r['speaker'] in their_speakers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also note that some of the texts are spoken by multiple people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>genre</th>\n",
       "      <th>play_name</th>\n",
       "      <th>scene</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_number</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>All's Well That Ends Well</td>\n",
       "      <td>3</td>\n",
       "      <td>Paris. The KING's palace.</td>\n",
       "      <td>all</td>\n",
       "      <td>34</td>\n",
       "      <td>We understand it, and thank heaven for you.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>4</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>All's Well That Ends Well</td>\n",
       "      <td>1</td>\n",
       "      <td>Without the Florentine camp.</td>\n",
       "      <td>all</td>\n",
       "      <td>26</td>\n",
       "      <td>Cargo, cargo, cargo, villiando par corbo, cargo.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Cymbeline</td>\n",
       "      <td>4</td>\n",
       "      <td>A British prison.</td>\n",
       "      <td>all</td>\n",
       "      <td>19</td>\n",
       "      <td>Thanks, Jupiter!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     act   genre                  play_name scene  \\\n",
       "268    2  Comedy  All's Well That Ends Well     3   \n",
       "587    4  Comedy  All's Well That Ends Well     1   \n",
       "3062   5  Comedy                  Cymbeline     4   \n",
       "\n",
       "                        scene_name speaker speech_number  \\\n",
       "268      Paris. The KING's palace.     all            34   \n",
       "587   Without the Florentine camp.     all            26   \n",
       "3062             A British prison.     all            19   \n",
       "\n",
       "                                           speech_text  female  \n",
       "268        We understand it, and thank heaven for you.   False  \n",
       "587   Cargo, cargo, cargo, villiando par corbo, cargo.   False  \n",
       "3062                                  Thanks, Jupiter!   False  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df[speeches_df.speaker.str.startswith('all')][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are examining differences in male/female speech in this analysis, we will discard all text spoken by multiple people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>genre</th>\n",
       "      <th>play_name</th>\n",
       "      <th>scene</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_number</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15272</th>\n",
       "      <td>3</td>\n",
       "      <td>History</td>\n",
       "      <td>Henry VIII</td>\n",
       "      <td>2</td>\n",
       "      <td>Ante-chamber to KING HENRY VIII's apartment.</td>\n",
       "      <td>suffolk</td>\n",
       "      <td>31</td>\n",
       "      <td>'Tis so.\\nThe cardinal!\\nEnter CARDINAL WOLSEY...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9831</th>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Taming of the Shrew</td>\n",
       "      <td>2</td>\n",
       "      <td>Padua. LUCENTIO'S house.</td>\n",
       "      <td>lucentio</td>\n",
       "      <td>90</td>\n",
       "      <td>But a harsh hearing when women are froward.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17300</th>\n",
       "      <td>3</td>\n",
       "      <td>History</td>\n",
       "      <td>Richard III</td>\n",
       "      <td>4</td>\n",
       "      <td>The Tower of London.</td>\n",
       "      <td>hastings</td>\n",
       "      <td>13</td>\n",
       "      <td>I thank your grace.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      act    genre            play_name scene  \\\n",
       "15272   3  History           Henry VIII     2   \n",
       "9831    5   Comedy  Taming of the Shrew     2   \n",
       "17300   3  History          Richard III     4   \n",
       "\n",
       "                                         scene_name   speaker speech_number  \\\n",
       "15272  Ante-chamber to KING HENRY VIII's apartment.   suffolk            31   \n",
       "9831                       Padua. LUCENTIO'S house.  lucentio            90   \n",
       "17300                          The Tower of London.  hastings            13   \n",
       "\n",
       "                                             speech_text  female  \n",
       "15272  'Tis so.\\nThe cardinal!\\nEnter CARDINAL WOLSEY...   False  \n",
       "9831         But a harsh hearing when women are froward.   False  \n",
       "17300                                I thank your grace.   False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.drop(speeches_df[speeches_df.speaker.str.startswith('all')].index, inplace = True)\n",
    "speeches_df.sample(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe with all the data that we need, we turn our attention to the imbalance in male/female texts. We will have to take this into account when fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female\n",
       "False    22275\n",
       "True      4728\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.groupby(['female']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 - male, 1 - female\n",
    "labels = [ 1 if f else 0 for f in speeches_df.female.values ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform text preprocessing, steming and tokenizing our words.\n",
    "\n",
    "This will not used in the final version as it makes CountVectorizer very slow. The built in functionality will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we note that we've successfully tokenized and stemmed our words.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Although before the solemn priest I have sworn,\n",
      "I will not bed her.\n"
     ]
    }
   ],
   "source": [
    "t = speeches_df.loc[334, 'speech_text']\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['although', 'befor', 'the', 'solemn', 'priest', 'I', 'have', 'sworn', ',', 'I', 'will', 'not', 'bed', 'her', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can begin the analysis, splitting our features into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = speeches_df['speech_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    stratify = labels, \n",
    "                                                    test_size = 0.10, \n",
    "                                                    random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a feature space, perform dimension reduction, and search for the best preforming parameters. We'll try three models: an SGDClassifier, RandomForestClassifier, and KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('pipeline_sgd', ignore_errors = True)\n",
    "os.makedirs('pipeline_sgd')\n",
    "\n",
    "pipe_sgd = Pipeline(\n",
    "    memory = 'pipeline',\n",
    "    steps=[\n",
    "        # Create feature space\n",
    "        ('vect', CountVectorizer(min_df=2, \n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True,\n",
    "                                 strip_accents='unicode')),\n",
    "                                 #ngram_range=(2,3))\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        # Perform LSA on the features\n",
    "        ('svd', TruncatedSVD()),\n",
    "        # faster than SVC, default loss is 'hinge'\n",
    "        ('clf', SGDClassifier(class_weight= 'balanced', \n",
    "                              verbose = 0, \n",
    "                              n_jobs = -1, \n",
    "                              max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_sgd = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'svd__n_components': [250, 300, 350],\n",
    "    'clf__alpha': [0.00001, 0.000001],\n",
    "    'clf__penalty': ('l2', 'elasticnet')\n",
    "}\n",
    "\n",
    "model_sgd = GridSearchCV(\n",
    "    pipe_sgd,\n",
    "    param_grid = param_grid_sgd,\n",
    "    cv = StratifiedKFold(random_state = 100),\n",
    "    scoring = 'f1',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('pipeline_rf', ignore_errors = True)\n",
    "os.makedirs('pipeline_rf')\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    memory = 'pipeline',\n",
    "    steps=[\n",
    "        # Create feature space\n",
    "        ('vect', CountVectorizer(min_df=2, \n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True,\n",
    "                                 strip_accents='unicode')),\n",
    "                                 #ngram_range=(2,3))\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        # Perform LSA on the features\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('rf', RandomForestClassifier(criterion='gini',\n",
    "                                       min_samples_split=2, \n",
    "                                       min_samples_leaf=1, \n",
    "                                       min_weight_fraction_leaf=0.0, \n",
    "                                       max_features='auto', \n",
    "                                       max_leaf_nodes=None, \n",
    "                                       min_impurity_decrease=0.0, \n",
    "                                       min_impurity_split=None, \n",
    "                                       bootstrap=True, \n",
    "                                       oob_score=False, \n",
    "                                       n_jobs=1, \n",
    "                                       random_state=None, \n",
    "                                       verbose=0, \n",
    "                                       warm_start=False, \n",
    "                                       class_weight=None))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_rf = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'svd__n_components': [250, 300, 350],\n",
    "    'rf__n_estimators':[5,10,15]\n",
    "}\n",
    "\n",
    "model_rf = GridSearchCV(\n",
    "    pipe_rf,\n",
    "    param_grid = param_grid_rf,\n",
    "    cv = StratifiedKFold(random_state = 100),\n",
    "    scoring = 'f1',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('pipeline_knn', ignore_errors = True)\n",
    "os.makedirs('pipeline_knn')\n",
    "\n",
    "pipe_knn = Pipeline(\n",
    "    memory = 'pipeline',\n",
    "    steps=[\n",
    "        # Create feature space\n",
    "        ('vect', CountVectorizer(min_df=2, \n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True,\n",
    "                                 strip_accents='unicode')),\n",
    "                                 #ngram_range=(2,3))\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        # Perform LSA on the features\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('knn',KNeighborsClassifier(weights='uniform', \n",
    "                                    algorithm='auto', \n",
    "                                    p=2, \n",
    "                                    metric='minkowski', \n",
    "                                    metric_params=None, \n",
    "                                    n_jobs=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_knn = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'svd__n_components': [250, 300, 350],\n",
    "    'knn__n_neighbors':[3,4,5,6,7,8]\n",
    "}\n",
    "\n",
    "model_knn = GridSearchCV(\n",
    "    pipe_knn,\n",
    "    param_grid = param_grid_knn,\n",
    "    cv = StratifiedKFold(random_state = 100),\n",
    "    scoring = 'f1',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 23.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 246.2min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 280.4min finished\n"
     ]
    }
   ],
   "source": [
    "model_sgd = model_sgd.fit(X_train, y_train)\n",
    "model_rf = model_rf.fit(X_train, y_train)\n",
    "model_knn = model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at how the model's performance varied with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__alpha clf__penalty  mean_test_score svd__n_components tfidf__norm\n",
      "0      1e-05           l2         0.283419               250          l1\n",
      "1      1e-05           l2         0.251819               250          l1\n",
      "2      1e-05           l2         0.321952               250          l2\n",
      "3      1e-05           l2         0.325283               250          l2\n",
      "4      1e-05           l2         0.289454               300          l1\n",
      "   mean_test_score rf__n_estimators svd__n_components tfidf__norm\n",
      "0         0.131355                5               250          l1\n",
      "1         0.145271                5               250          l1\n",
      "2         0.141113                5               250          l2\n",
      "3         0.138767                5               250          l2\n",
      "4         0.131378                5               300          l1\n",
      "  knn__n_neighbors  mean_test_score svd__n_components tfidf__norm\n",
      "0                3         0.152070               250          l1\n",
      "1                3         0.152254               250          l1\n",
      "2                3         0.152794               250          l2\n",
      "3                3         0.161234               250          l2\n",
      "4                3         0.154261               300          l1\n"
     ]
    }
   ],
   "source": [
    "results_sgd = pd.DataFrame({'mean_test_score': np.array(model_sgd.cv_results_['mean_test_score']),\n",
    "                        'tfidf__norm': np.array(model_sgd.cv_results_['param_tfidf__norm']),\n",
    "                        'svd__n_components': np.array(model_sgd.cv_results_['param_svd__n_components']),\n",
    "                        'clf__alpha': np.array(model_sgd.cv_results_['param_clf__alpha']),\n",
    "                        'clf__penalty': np.array(model_sgd.cv_results_['param_clf__penalty'])})\n",
    "\n",
    "results_rf = pd.DataFrame({'mean_test_score': np.array(model_rf.cv_results_['mean_test_score']),\n",
    "                        'tfidf__norm': np.array(model_rf.cv_results_['param_tfidf__norm']),\n",
    "                        'svd__n_components': np.array(model_rf.cv_results_['param_svd__n_components']),\n",
    "                        'rf__n_estimators': np.array(model_rf.cv_results_['param_rf__n_estimators'])})\n",
    "\n",
    "results_knn = pd.DataFrame({'mean_test_score': np.array(model_knn.cv_results_['mean_test_score']),\n",
    "                        'tfidf__norm': np.array(model_knn.cv_results_['param_tfidf__norm']),\n",
    "                        'svd__n_components': np.array(model_knn.cv_results_['param_svd__n_components']),\n",
    "                        'knn__n_neighbors': np.array(model_knn.cv_results_['param_knn__n_neighbors'])})\n",
    "\n",
    "print(results_sgd.head())\n",
    "print(results_rf.head())\n",
    "print(results_knn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the best set of parameters for each of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'clf__alpha': 1e-05, 'clf__penalty': 'elasticnet', 'svd__n_components': 350, 'tfidf__norm': 'l2', 'vect__ngram_range': (1, 1)} with a score of 0.34\n",
      "\n",
      "The best parameters are {'rf__n_estimators': 5, 'svd__n_components': 250, 'tfidf__norm': 'l1', 'vect__ngram_range': (1, 2)} with a score of 0.15\n",
      "\n",
      "The best parameters are {'knn__n_neighbors': 3, 'svd__n_components': 350, 'tfidf__norm': 'l2', 'vect__ngram_range': (1, 2)} with a score of 0.16\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters are %s with a score of %0.2f\" % (model_sgd.best_params_, model_sgd.best_score_))\n",
    "print()\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (model_rf.best_params_, model_rf.best_score_))\n",
    "print()\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (model_knn.best_params_, model_knn.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can test on our test data and compare the results of the best set of parameters for each of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_sgd = model_sgd.predict(X_test)\n",
    "y_hat_rf = model_rf.predict(X_test)\n",
    "y_hat_knn = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.65      0.74      2228\n",
      "          1       0.23      0.49      0.31       473\n",
      "\n",
      "avg / total       0.75      0.62      0.66      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.93      0.88      2228\n",
      "          1       0.22      0.09      0.13       473\n",
      "\n",
      "avg / total       0.72      0.78      0.75      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.93      0.87      2228\n",
      "          1       0.19      0.08      0.12       473\n",
      "\n",
      "avg / total       0.72      0.78      0.74      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
